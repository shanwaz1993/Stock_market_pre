{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3653 entries, 2007-01-01 to 2016-12-31\n",
      "Freq: D\n",
      "Data columns (total 3 columns):\n",
      "close        3653 non-null float64\n",
      "adj close    3653 non-null float64\n",
      "articles     3653 non-null object\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 114.2+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-01</th>\n",
       "      <td>12469.971875</td>\n",
       "      <td>12469.971875</td>\n",
       "      <td>. What Sticks from '06. Somalia Orders Islamis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-02</th>\n",
       "      <td>12472.245703</td>\n",
       "      <td>12472.245703</td>\n",
       "      <td>. Heart Health: Vitamin Does Not Prevent Death...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>12474.519531</td>\n",
       "      <td>12474.519531</td>\n",
       "      <td>. Google Answer to Filling Jobs Is an Algorith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>12480.690430</td>\n",
       "      <td>12480.690430</td>\n",
       "      <td>. Helping Make the Shift From Combat to Commer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>12398.009766</td>\n",
       "      <td>12398.009766</td>\n",
       "      <td>. Rise in Ethanol Raises Concerns About Corn a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   close     adj close  \\\n",
       "2007-01-01  12469.971875  12469.971875   \n",
       "2007-01-02  12472.245703  12472.245703   \n",
       "2007-01-03  12474.519531  12474.519531   \n",
       "2007-01-04  12480.690430  12480.690430   \n",
       "2007-01-05  12398.009766  12398.009766   \n",
       "\n",
       "                                                     articles  \n",
       "2007-01-01  . What Sticks from '06. Somalia Orders Islamis...  \n",
       "2007-01-02  . Heart Health: Vitamin Does Not Prevent Death...  \n",
       "2007-01-03  . Google Answer to Filling Jobs Is an Algorith...  \n",
       "2007-01-04  . Helping Make the Shift From Combat to Commer...  \n",
       "2007-01-05  . Rise in Ethanol Raises Concerns About Corn a...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocks = pd.read_pickle('/home/shan/stock_market/Stock_Market_Prediction/Data/Pickled_data.pkl')\n",
    "print(df_stocks.info())\n",
    "df_stocks.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 3653 entries, 2007-01-01 to 2016-12-31\n",
      "Freq: D\n",
      "Data columns (total 4 columns):\n",
      "close        3653 non-null float64\n",
      "adj close    3653 non-null float64\n",
      "articles     3653 non-null object\n",
      "prices       3653 non-null int64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 142.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_stocks['prices'] = df_stocks['adj close'].apply(np.int64)\n",
    "print(df_stocks.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the prices and articles\n",
    "df_stocks = df_stocks[['prices', 'articles']]\n",
    "df_stocks['articles'] = df_stocks['articles'].map(lambda x: x.lstrip('.-'))\n",
    "#print(df_stocks.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_stocks[['prices']].copy()\n",
    "#print(df.head())\n",
    "df[\"compound\"] = ''\n",
    "df[\"neg\"] = ''\n",
    "df[\"neu\"] = ''\n",
    "df[\"pos\"] = ''\n",
    "df.head()\n",
    "df_stocks.articles.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now starts score prediction for given sentence.\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "import unicodedata\n",
    "saf = SentimentIntensityAnalyzer()   #df_stocks.T provides the transpose of data.\n",
    "T_df_stocks=df_stocks.T\n",
    "#print(T_df_stocks.head())\n",
    "\n",
    "for date, row in df_stocks.T.iteritems():\n",
    "    try:\n",
    "        sentence = unicodedata.normalize('NFKD', df_stocks.loc[date, 'articles'])\n",
    "        #print(sentence)\n",
    "        ss = saf.polarity_scores(sentence)\n",
    "        df.at(date, 'compound', ss['compound'])\n",
    "        df.at(date, 'neg', ss['neg'])\n",
    "        df.at(date, 'neu', ss['neu'])\n",
    "        df.at(date, 'pos', ss['pos'])\n",
    "    except TypeError:\n",
    "        #print (df_stocks.loc[date, 'articles'].head())\n",
    "        date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prices</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2007-01-01</th>\n",
       "      <td>12469</td>\n",
       "      <td>-0.9814</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-02</th>\n",
       "      <td>12472</td>\n",
       "      <td>-0.8179</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-03</th>\n",
       "      <td>12474</td>\n",
       "      <td>-0.9993</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-04</th>\n",
       "      <td>12480</td>\n",
       "      <td>-0.9982</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-01-05</th>\n",
       "      <td>12398</td>\n",
       "      <td>-0.9901</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            prices compound    neg    neu    pos\n",
       "2007-01-01   12469  -0.9814  0.159  0.749  0.093\n",
       "2007-01-02   12472  -0.8179  0.114  0.787  0.099\n",
       "2007-01-03   12474  -0.9993  0.198  0.737  0.065\n",
       "2007-01-04   12480  -0.9982  0.131  0.806  0.062\n",
       "2007-01-05   12398  -0.9901  0.124  0.794  0.082"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.423, 'neu': 0.577, 'pos': 0.0, 'compound': -0.296}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentence = 'paris shootout police officer suspected guman dead'\n",
    "#sentence ='ohh no icici deal '\n",
    "#from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#import unicodedata\n",
    "#sid = SentimentIntensityAnalyzer()\n",
    "#ss = sid.polarity_scores(sentence)\n",
    "#ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            prices compound    neg    neu    pos\n",
      "2007-01-01   12469  -0.9814  0.159  0.749  0.093\n",
      "2007-01-02   12472  -0.8179  0.114  0.787  0.099\n",
      "2007-01-03   12474  -0.9993  0.198  0.737  0.065\n",
      "2007-01-04   12480  -0.9982  0.131  0.806  0.062\n",
      "2007-01-05   12398  -0.9901  0.124  0.794  0.082\n",
      "            prices compound    neg    neu    pos\n",
      "2015-01-01   17828  -0.9299  0.138   0.74  0.122\n",
      "2015-01-02   17832  -0.9775  0.149  0.759  0.093\n",
      "2015-01-03   17722  -0.9737  0.131  0.787  0.083\n",
      "2015-01-04   17612  -0.9971   0.22  0.716  0.064\n",
      "2015-01-05   17501  -0.9905  0.156  0.767  0.077\n"
     ]
    }
   ],
   "source": [
    "train_start_date = '2007-01-01'\n",
    "train_end_date = '2014-12-31'\n",
    "test_start_date = '2015-01-01'\n",
    "test_end_date = '2016-12-31'\n",
    "train = df.loc[train_start_date : train_end_date]\n",
    "test = df.loc[test_start_date:test_end_date]\n",
    "print(train.head())\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.159, 0.093],\n",
       "       [0.114, 0.099],\n",
       "       [0.198, 0.065],\n",
       "       ...,\n",
       "       [0.171, 0.075],\n",
       "       [0.16 , 0.14 ],\n",
       "       [0.198, 0.135]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score_list = []\n",
    "for date, row in train.T.iteritems():\n",
    "    #sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "    sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "    sentiment_score_list.append(sentiment_score)\n",
    "numpy_df_train = np.asarray(sentiment_score_list)\n",
    "numpy_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.138, 0.122],\n",
       "       [0.149, 0.093],\n",
       "       [0.131, 0.083],\n",
       "       ...,\n",
       "       [0.138, 0.097],\n",
       "       [0.168, 0.098],\n",
       "       [0.173, 0.161]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score_list = []\n",
    "for date, row in test.T.iteritems():\n",
    "    #sentiment_score = np.asarray([df.loc[date, 'compound'],df.loc[date, 'neg'],df.loc[date, 'neu'],df.loc[date, 'pos']])\n",
    "    sentiment_score = np.asarray([df.loc[date, 'neg'],df.loc[date, 'pos']])\n",
    "    sentiment_score_list.append(sentiment_score)\n",
    "numpy_df_test = np.asarray(sentiment_score_list)\n",
    "numpy_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            prices\n",
      "2007-01-01   12469\n",
      "2007-01-02   12472\n",
      "2007-01-03   12474\n",
      "2007-01-04   12480\n",
      "2007-01-05   12398\n",
      "2007-01-06   12406\n",
      "2007-01-07   12414\n",
      "2007-01-08   12423\n",
      "2007-01-09   12416\n",
      "2007-01-10   12442\n",
      "2007-01-11   12514\n",
      "2007-01-12   12556\n",
      "2007-01-13   12562\n",
      "2007-01-14   12569\n",
      "2007-01-15   12575\n",
      "2007-01-16   12582\n",
      "2007-01-17   12577\n",
      "2007-01-18   12567\n",
      "2007-01-19   12565\n",
      "2007-01-20   12536\n",
      "2007-01-21   12506\n",
      "2007-01-22   12477\n",
      "2007-01-23   12533\n",
      "2007-01-24   12621\n",
      "2007-01-25   12502\n",
      "2007-01-26   12487\n",
      "2007-01-27   12488\n",
      "2007-01-28   12489\n",
      "2007-01-29   12490\n",
      "2007-01-30   12523\n",
      "...            ...\n",
      "2014-12-02   17879\n",
      "2014-12-03   17912\n",
      "2014-12-04   17900\n",
      "2014-12-05   17958\n",
      "2014-12-06   17923\n",
      "2014-12-07   17887\n",
      "2014-12-08   17852\n",
      "2014-12-09   17801\n",
      "2014-12-10   17533\n",
      "2014-12-11   17596\n",
      "2014-12-12   17280\n",
      "2014-12-13   17247\n",
      "2014-12-14   17214\n",
      "2014-12-15   17180\n",
      "2014-12-16   17068\n",
      "2014-12-17   17356\n",
      "2014-12-18   17778\n",
      "2014-12-19   17804\n",
      "2014-12-20   17856\n",
      "2014-12-21   17907\n",
      "2014-12-22   17959\n",
      "2014-12-23   18024\n",
      "2014-12-24   18030\n",
      "2014-12-25   18041\n",
      "2014-12-26   18053\n",
      "2014-12-27   18048\n",
      "2014-12-28   18043\n",
      "2014-12-29   18038\n",
      "2014-12-30   17983\n",
      "2014-12-31   17823\n",
      "\n",
      "[2922 rows x 1 columns]\n",
      "            prices\n",
      "2015-01-01   17828\n",
      "2015-01-02   17832\n",
      "2015-01-03   17722\n",
      "2015-01-04   17612\n",
      "2015-01-05   17501\n",
      "2015-01-06   17371\n",
      "2015-01-07   17584\n",
      "2015-01-08   17907\n",
      "2015-01-09   17737\n",
      "2015-01-10   17705\n",
      "2015-01-11   17673\n",
      "2015-01-12   17640\n",
      "2015-01-13   17613\n",
      "2015-01-14   17427\n",
      "2015-01-15   17320\n",
      "2015-01-16   17511\n",
      "2015-01-17   17512\n",
      "2015-01-18   17513\n",
      "2015-01-19   17514\n",
      "2015-01-20   17515\n",
      "2015-01-21   17554\n",
      "2015-01-22   17813\n",
      "2015-01-23   17672\n",
      "2015-01-24   17674\n",
      "2015-01-25   17676\n",
      "2015-01-26   17678\n",
      "2015-01-27   17387\n",
      "2015-01-28   17191\n",
      "2015-01-29   17416\n",
      "2015-01-30   17164\n",
      "...            ...\n",
      "2016-12-02   19170\n",
      "2016-12-03   19185\n",
      "2016-12-04   19200\n",
      "2016-12-05   19216\n",
      "2016-12-06   19251\n",
      "2016-12-07   19549\n",
      "2016-12-08   19614\n",
      "2016-12-09   19756\n",
      "2016-12-10   19770\n",
      "2016-12-11   19783\n",
      "2016-12-12   19796\n",
      "2016-12-13   19911\n",
      "2016-12-14   19792\n",
      "2016-12-15   19852\n",
      "2016-12-16   19843\n",
      "2016-12-17   19856\n",
      "2016-12-18   19869\n",
      "2016-12-19   19883\n",
      "2016-12-20   19974\n",
      "2016-12-21   19941\n",
      "2016-12-22   19918\n",
      "2016-12-23   19933\n",
      "2016-12-24   19936\n",
      "2016-12-25   19939\n",
      "2016-12-26   19942\n",
      "2016-12-27   19945\n",
      "2016-12-28   19833\n",
      "2016-12-29   19819\n",
      "2016-12-30   19762\n",
      "2016-12-31   19762\n",
      "\n",
      "[731 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.DataFrame(train['prices'])\n",
    "y_test = pd.DataFrame(test['prices'])\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shan/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/shan/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53718281 0.46281719]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(numpy_df_train, y_train)\n",
    "print (rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'treeinterpreter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-28597ec3d76c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtreeinterpreter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtreeinterpreter\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mti\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontributions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_df_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'treeinterpreter'"
     ]
    }
   ],
   "source": [
    "from treeinterpreter import treeinterpreter as ti\n",
    "prediction, bias, contributions = ti.predict(rf, numpy_df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
